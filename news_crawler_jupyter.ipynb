{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 API를 활용한 데이터 수집 실습\n",
    "\n",
    "## 들어가며\n",
    "이 실습에서는 네이버 뉴스 검색 API를 활용하여 실시간으로 뉴스 데이터를 수집하고 분석하는 방법을 배웁니다. \n",
    "데이터 수집의 기초부터 데이터 정제, 저장, 그리고 기본적인 분석까지의 전 과정을 파이썬으로 구현해보면서 \n",
    "실제 데이터 과학 프로젝트의 흐름을 경험해 볼 수 있습니다.\n",
    "\n",
    "## 학습 목표\n",
    "1. **API의 개념과 활용**: 외부 서비스 API를 통한 데이터 수집 방법 이해\n",
    "2. **HTTP 통신 기초**: 요청과 응답 구조, 헤더와 파라미터 활용법 습득\n",
    "3. **JSON 데이터 처리**: JSON 형식의 데이터를 파싱하고 활용하는 방법 학습\n",
    "4. **HTML 처리 기술**: Beautiful Soup을 활용한 HTML 태그 제거 및 텍스트 추출\n",
    "5. **데이터 저장**: 수집한 데이터를 엑셀 파일로 저장하는 다양한 방법 습득\n",
    "6. **데이터 분석 기초**: 판다스를 활용한 기본 데이터 분석 및 시각화 경험\n",
    "\n",
    "## 사전 준비사항\n",
    "- Python 기본 문법에 대한 이해\n",
    "- Jupyter Notebook 사용법 숙지\n",
    "- 필요 라이브러리 설치 (`requests`, `beautifulsoup4`, `pandas`, `openpyxl`)\n",
    "\n",
    "이 실습을 마치면 여러분은 실제 데이터를 수집하고 처리하는 능력을 갖추게 될 것입니다. \n",
    "이러한 기술은 데이터 분석, 머신러닝, 그리고 자연어 처리 분야에서 매우 중요한 기초가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 임포트\n",
    "\n",
    "데이터 수집과 처리를 위해 다음과 같은 라이브러리들을 사용합니다:\n",
    "\n",
    "- **requests**: 웹 서버에 HTTP 요청을 보내고 응답을 받는 기능을 제공합니다.\n",
    "- **json**: JSON 형식의 데이터를 파이썬 객체로 변환하거나, 파이썬 객체를 JSON으로 변환하는 기능을 제공합니다.\n",
    "- **BeautifulSoup**: HTML 또는 XML 문서를 파싱하고 데이터를 추출하는 기능을 제공합니다.\n",
    "- **pandas**: 데이터 분석과 조작을 위한 고성능 도구를 제공합니다.\n",
    "- **re**: 정규표현식을 사용하여 텍스트를 처리하는 기능을 제공합니다.\n",
    "- **openpyxl**: 엑셀 파일(.xlsx)을 읽고 쓰는 기능을 제공합니다.\n",
    "\n",
    "만약 이러한 라이브러리가 설치되어 있지 않다면, 다음과 같이 설치할 수 있습니다:\n",
    "```\n",
    "pip install requests beautifulsoup4 pandas openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import requests  # HTTP 요청을 보내기 위한 라이브러리\n",
    "import json  # JSON 데이터 처리를 위한 라이브러리\n",
    "from bs4 import BeautifulSoup  # HTML 파싱을 위한 라이브러리\n",
    "import pandas as pd  # 데이터 처리를 위한 라이브러리\n",
    "import re  # 정규표현식을 사용하기 위한 라이브러리\n",
    "import openpyxl  # 엑셀 파일 처리를 위한 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API 인증 정보 설정\n",
    "\n",
    "네이버에서는 개발자들에게 다양한 API 서비스를 제공하고 있습니다. 이러한 API를 사용하기 위해서는 인증 정보가 필요합니다.\n",
    "\n",
    "### 네이버 API 인증 정보 발급 방법\n",
    "1. 네이버 개발자 센터(https://developers.naver.com)에 접속합니다.\n",
    "2. 회원가입 및 로그인 후 \"애플리케이션 등록\" 메뉴를 선택합니다.\n",
    "3. \"애플리케이션 이름\"과 사용할 API를 선택하고 필요한 정보를 입력합니다.\n",
    "4. 등록 완료 후 \"Client ID\"와 \"Client Secret\"을 발급받습니다.\n",
    "\n",
    "### 중요한 보안 사항\n",
    "* API 키는 개인 정보와 같이 중요한 보안 정보입니다.\n",
    "* 실제 프로젝트에서는 코드에 직접 입력하지 말고, 환경 변수나 별도의 설정 파일에서 불러오는 것이 좋습니다.\n",
    "* Git과 같은 버전 관리 시스템에 API 키를 포함하지 않도록 주의해야 합니다.\n",
    "\n",
    "**참고**: 이 실습에서는 제공된 API 키를 사용하지만, 실제 프로젝트에서는 본인의 API 키를 발급받아 사용하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 개발자 센터에서 발급받은 API 인증 정보\n",
    "client_id = \"yR8aViAqV5NyEjZpfo74\"  # 네이버 API 클라이언트 ID\n",
    "client_secret = \"SQ_PTt2epk\"  # 네이버 API 클라이언트 시크릿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 검색어 입력 및 API 요청 설정\n",
    "\n",
    "API를 통해 검색 결과를 가져오기 위해 사용자로부터 검색어를 입력받고, API 요청에 필요한 URL과 헤더를 설정합니다.\n",
    "\n",
    "### 주요 개념\n",
    "- **URL 파라미터**: API 요청시 검색어(`query`), 결과 개수(`display`) 등을 URL에 포함시켜 전달합니다.\n",
    "- **요청 헤더**: API 인증을 위해 클라이언트 ID와 시크릿 키를 헤더에 포함시킵니다.\n",
    "- **f-string**: 파이썬 3.6 이상에서 제공하는 문자열 포맷팅 방식으로, 변수를 문자열 안에 쉽게 삽입할 수 있습니다.\n",
    "\n",
    "### 네이버 API 매개변수\n",
    "- `query`: 검색어 (필수)\n",
    "- `display`: 검색 결과 출력 건수 (기본값: 10, 최대: 100)\n",
    "- `start`: 검색 시작 위치 (기본값: 1, 최대: 1000)\n",
    "- `sort`: 정렬 옵션 (`sim`: 유사도순, `date`: 날짜순)\n",
    "\n",
    "다음 코드를 통해 사용자로부터 검색어를 입력받고 API 요청을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자로부터 검색어 입력 받기\n",
    "query = input(\"검색할 키워드를 입력하세요: \")  # 검색할 키워드 입력\n",
    "display = 10  # 한 번에 가져올 검색 결과 개수 (최대 100개까지 설정 가능)\n",
    "\n",
    "# 네이버 뉴스 검색 API URL 생성\n",
    "url = f\"https://openapi.naver.com/v1/search/news.json?query={query}&display={display}\"\n",
    "\n",
    "# API 요청 헤더 설정\n",
    "headers = {\n",
    "    \"X-Naver-Client-Id\": client_id,\n",
    "    \"X-Naver-Client-Secret\": client_secret,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API 요청 및 응답 처리\n",
    "\n",
    "설정한 URL과 헤더를 사용하여 API 요청을 보내고, 응답을 처리합니다.\n",
    "\n",
    "### 코드 설명\n",
    "- `requests.get()`: HTTP GET 요청을 보내는 함수입니다. URL과 헤더 정보를 인자로 전달합니다.\n",
    "- `response.status_code`: HTTP 응답 상태 코드로, 요청이 성공했는지 여부를 확인할 수 있습니다.\n",
    "  - 200: 요청 성공\n",
    "  - 400: 잘못된 요청\n",
    "  - 401: 인증 실패\n",
    "  - 404: 리소스를 찾을 수 없음\n",
    "  - 500: 서버 내부 오류\n",
    "- `response.json()`: 응답 데이터를 JSON 형식으로 파싱합니다.\n",
    "\n",
    "### 예외 처리\n",
    "API 요청 시에는 항상 응답 상태 코드를 확인하여 요청이 성공적으로 처리되었는지 확인하는 것이 중요합니다. 이를 통해 오류 발생 시 적절한 처리를 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답 상태 코드: 200\n",
      "총 10개의 뉴스 기사를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# API 요청 보내기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 응답 상태 코드 확인\n",
    "print(f\"응답 상태 코드: {response.status_code}\")\n",
    "\n",
    "# 응답이 성공적인 경우 (상태 코드 200)\n",
    "if response.status_code == 200:\n",
    "    # JSON 응답 데이터 파싱\n",
    "    news_data = response.json()\n",
    "    \n",
    "    # 검색 결과 항목 수 출력\n",
    "    if 'items' in news_data:\n",
    "        print(f\"총 {len(news_data['items'])}개의 뉴스 기사를 찾았습니다.\")\n",
    "    else:\n",
    "        print(\"검색 결과가 없습니다.\")\n",
    "else:\n",
    "    print(f\"API 요청 실패: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 검색 결과 데이터 확인\n",
    "\n",
    "API 응답으로 받은 JSON 데이터의 구조를 확인합니다. JSON(JavaScript Object Notation)은 데이터를 교환하는 데 널리 사용되는 형식입니다.\n",
    "\n",
    "### JSON 데이터 구조 이해하기\n",
    "네이버 뉴스 API는 다음과 같은 구조의 JSON 데이터를 반환합니다:\n",
    "- `lastBuildDate`: 검색 결과 생성 시간\n",
    "- `total`: 검색 결과 총 개수\n",
    "- `start`: 검색 결과 시작 위치\n",
    "- `display`: 한 번에 표시되는 검색 결과 개수\n",
    "- `items`: 뉴스 기사 항목 배열\n",
    "  - `title`: 뉴스 제목\n",
    "  - `originallink`: 뉴스 원본 링크\n",
    "  - `link`: 네이버 뉴스 링크\n",
    "  - `description`: 뉴스 내용 요약\n",
    "  - `pubDate`: 발행 날짜\n",
    "\n",
    "아래 코드에서는 `json.dumps()` 함수를 사용하여 첫 번째 뉴스 항목을 보기 좋게 출력합니다. `indent` 파라미터는 들여쓰기를, `ensure_ascii=False`는 한글이 깨지지 않도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 뉴스 항목 데이터:\n",
      "{\n",
      "  \"title\": \"경기도교육청, 'AI 서·논술형 평가 역량 강화' 박차…올해 교원 4천 명...\",\n",
      "  \"originallink\": \"https://www.cstimes.com/news/articleView.html?idxno=647434\",\n",
      "  \"link\": \"https://www.cstimes.com/news/articleView.html?idxno=647434\",\n",
      "  \"description\": \"경기도교육청 남부신청사 컨슈머타임스=안우진 기자 | 경기도교육청(교육감 임태희)이 <b>인공지능</b>(AI) 기반 서·논술형 평가 선도 교원을 본격 양성한다. 경기도교육청은 지난 3월 <b>인공지능</b>(AI) 서·논술형 평가... \",\n",
      "  \"pubDate\": \"Sat, 17 May 2025 01:00:00 +0900\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# API 응답 데이터 구조 확인 (첫 번째 항목만)\n",
    "if response.status_code == 200 and 'items' in news_data and len(news_data['items']) > 0:\n",
    "    print(\"첫 번째 뉴스 항목 데이터:\")\n",
    "    print(json.dumps(news_data['items'][0], indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"데이터를 표시할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 검색 결과 처리 및 엑셀 파일 저장\n",
    "\n",
    "검색 결과에서 제목과 본문을 추출하고, HTML 태그를 제거한 후 엑셀 파일로 저장합니다.\n",
    "\n",
    "### 데이터 정제 과정\n",
    "1. **HTML 강조 태그 제거**: 네이버 검색 API는 검색어와 일치하는 부분을 `<b>` 태그로 강조합니다. 이 태그를 제거하여 텍스트만 추출합니다.\n",
    "2. **HTML 태그 제거**: BeautifulSoup 라이브러리를 사용하여 남아있는 HTML 태그를 제거하고 순수 텍스트를 추출합니다.\n",
    "\n",
    "### 엑셀 파일 저장 과정\n",
    "1. **워크북 생성**: openpyxl을 사용하여 새 엑셀 파일을 생성합니다.\n",
    "2. **데이터 추가**: 추출한 제목과 본문을 행으로 추가합니다.\n",
    "3. **파일 저장**: 검색어를 파일명에 포함하여 저장합니다.\n",
    "\n",
    "이 과정을 통해 웹에서 가져온 데이터를 구조화된 형태로 저장하고 추후 분석에 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: 경기도교육청, 'AI 서·논술형 평가 역량 강화' 박차…올해 교원 4천 명...\n",
      "본문: 경기도교육청 남부신청사 컨슈머타임스=안우진 기자 | 경기도교육청(교육감 임태희)이 인공지능(AI) 기반 서·논술형 평가 선도 교원을 본격 양성한다. 경기도교육청은 지난 3월 인공지능(AI) 서·논술형 평가... \n",
      "--------------------------------------------------\n",
      "제목: 한화세미텍과 한미반도체, SK하이닉스에 HBM 장비 공급 계약 체결\n",
      "본문: TC본더는 인공지능(AI) 반도체용 HBM 제조에 필수적인 장비로, D램을 고정하는 공정에서 사용된다. 글로벌 HBM 시장은 AI 수요 증가로 인해 빠르게 성장하고 있으며, 2025년에는 467억달러 규모로 확대될 전망이다.... \n",
      "--------------------------------------------------\n",
      "제목: 한국수자원공사, '생태자연 분야 데이터 활용' 새로운 부가가치 확산 논...\n",
      "본문: 이를 바탕으로 생태자연 분야 데이터의 생산 및 분석 현황과 인공지능(AI), 디지털트윈 등 디지털 기술과의 연계를 집중 조명하고, 환경 분야 관계 기관 및 관련 산업 분야와 협력을 넓혀 나가는 창구로서 빅데이터... \n",
      "--------------------------------------------------\n",
      "제목: 도성훈 교육감, 콜롬비아 교사 대상 '디지털 대전환 시대, 읽걷쓰 교육...\n",
      "본문: 이번 특강은 도성훈 교육감이 지난 4월 콜롬비아를 방문해 인공지능(AI)·디지털 교육 정책 협력과'읽걷쓰'교육 가치에 대한 공감대를 형성한 것에 대한 후속 조치로 이루어졌다. 콜롬비아 교육부는 자국의 인공지능(AI)... \n",
      "--------------------------------------------------\n",
      "제목: 경복대 의료미용학과, 대학축제 맞아 유노성형외과 후원 '커피차 행사'...\n",
      "본문: 경복대학교 의료미용학과는 'K-메디컬뷰티 실무 전문가 양성'을 교육 비전으로 삼고 있으며 4차 산업혁명과 디지털 헬스케어 시대에 맞춰 인공지능(AI), 피부 분석 시스템, AR/VR 기술 등을 활용한 차세대 의료미용 교육을... \n",
      "--------------------------------------------------\n",
      "제목: “청렴하고 행정 능력 갖춘 金, 대장선에 타고 나홀로 싸워… 남은 12척...\n",
      "본문: 김 후보가 내게 의료와 AI(인공지능) 분야는 꼭 좀 맡아달라고 해서 힘을 쏟고 있다.” -김 후보의 강점이 뭔가. “일을 할 줄 아는 행정가라는 것이다. 경기연구원에서 집계한 경기도 경제성장률 자료를 보면 2014~2018년... \n",
      "--------------------------------------------------\n",
      "제목: 탈원전 앞장선 벨기에·덴마크 “다시 원전이다”\n",
      "본문: AI(인공지능) 확산과 전기차 보급 등에 따라 2050년 전력 수요가 지금의 2배 수준으로 폭증할 것이라는 분석이 나오는 가운데 안정적이고 값싼 에너지원인 원전이 대세로 자리 잡고 있는 것이다. 16일 프랑스 일간 르몽드... \n",
      "--------------------------------------------------\n",
      "제목: AI시대 동력… 李 “재생에너지 확대” 金 “원전 비율 2배로”\n",
      "본문: [3] 에너지 정책 어떻게 다른가 이재명 더불어민주당 후보와 김문수 국민의힘 후보의 에너지 공약은 모두 AI(인공지능) 시대에 초점을 맞추고 있다. AI 확산에 따라 급격히 늘어나는 전력 수요에 에너지 정책의 중심을... \n",
      "--------------------------------------------------\n",
      "제목: 중동 3국 돌고 나니 2791조원 ‘수퍼딜’\n",
      "본문: 트럼프는 이날 마지막 순방국 아랍에미리트(UAE)에서 무함마드 빈 자이드 알 나하얀 UAE 대통령과 정상회담을 하고 미국산 인공지능(AI) 반도체 칩 연간 50만개 수출, 200억달러 규모 기술 협력 등의 성과를 발표했다. UAE는... \n",
      "--------------------------------------------------\n",
      "제목: 노동자 권리 지지했으나 마르크스주의엔 선 그은 레오 13세\n",
      "본문: “오늘날 교회와 인류 사회는 인공지능(AI)의 급격한 발전이라는 새로운 산업혁명에 직면하고 있다. 레오 13세의 가르침을 통해 인간의 존엄성과 정의, 노동의 가치 등 (AI가 제기할 수 있는) 도전에 지혜롭게 대응해... \n",
      "--------------------------------------------------\n",
      "'인공지능_news.xlsx' 파일에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25058/386099584.py:19: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  clean_content = BeautifulSoup(content, \"html.parser\").text\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    # Openpyxl을 사용하여 새 워크북 생성\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"네이버 뉴스 검색 결과\"\n",
    "    \n",
    "    # 열 제목 추가\n",
    "    ws.append([\"제목\", \"본문\"])\n",
    "    \n",
    "    if 'items' in news_data:\n",
    "        # 검색 결과가 있는 경우 처리 시작\n",
    "        for item in news_data['items']:\n",
    "            # HTML 강조 태그(<b></b>)를 제거하여 제목과 본문 텍스트 추출\n",
    "            title = item['title'].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
    "            content = item['description'].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
    "            \n",
    "            # BeautifulSoup을 사용하여 남아있는 HTML 태그를 제거하고 순수 텍스트 추출\n",
    "            clean_title = BeautifulSoup(title, \"html.parser\").text\n",
    "            clean_content = BeautifulSoup(content, \"html.parser\").text\n",
    "            \n",
    "            # 추출한 제목과 본문을 콘솔에 출력\n",
    "            print(f\"제목: {clean_title}\")\n",
    "            print(f\"본문: {clean_content}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # 추출한 제목과 본문을 엑셀 워크시트에 추가\n",
    "            ws.append([clean_title, clean_content])\n",
    "        \n",
    "        # 엑셀 파일 저장\n",
    "        file_name = f\"{query}_news.xlsx\"\n",
    "        wb.save(file_name)\n",
    "        print(f\"'{file_name}' 파일에 저장되었습니다.\")\n",
    "    else:\n",
    "        # 검색 결과가 없는 경우 메시지 출력\n",
    "        print(\"검색 결과가 없습니다.\")\n",
    "else:\n",
    "    # API 요청이 실패한 경우 오류 코드와 함께 메시지 출력\n",
    "    print(\"API 요청 실패:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 판다스를 활용한 데이터 분석 (선택 사항)\n",
    "\n",
    "저장된 데이터를 판다스 데이터프레임으로 변환하여 추가 분석을 수행할 수 있습니다. 판다스(pandas)는 데이터 분석과 조작을 위한 강력한 파이썬 라이브러리로, 다양한 형태의 데이터를 효과적으로 다룰 수 있게 해줍니다.\n",
    "\n",
    "### 판다스 데이터프레임의 장점\n",
    "- 행과 열 구조로 데이터를 직관적으로 표현\n",
    "- 다양한 데이터 소스에서 데이터 로드 가능 (CSV, Excel, SQL 등)\n",
    "- 강력한 필터링, 그룹화, 집계 기능 제공\n",
    "- 시각화 도구와의 손쉬운 연계\n",
    "\n",
    "### 추가 분석 가능성\n",
    "1. **텍스트 분석**: 뉴스 본문에 자주 등장하는 키워드 분석\n",
    "2. **감정 분석**: 뉴스 기사의 긍정/부정 분위기 파악\n",
    "3. **기사 분류**: 주제에 따른 기사 자동 분류 시스템 구축\n",
    "4. **트렌드 분석**: 시간에 따른 키워드 변화 추적\n",
    "\n",
    "다음 코드에서는 수집한 뉴스 데이터를 판다스 데이터프레임으로 변환하고, 필요에 따라 CSV 파일로 저장하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             제목  \\\n",
      "0  경기도교육청, 'AI 서·논술형 평가 역량 강화' 박차…올해 교원 4천 명...   \n",
      "1         한화세미텍과 한미반도체, SK하이닉스에 HBM 장비 공급 계약 체결   \n",
      "2    한국수자원공사, '생태자연 분야 데이터 활용' 새로운 부가가치 확산 논...   \n",
      "3    도성훈 교육감, 콜롬비아 교사 대상 '디지털 대전환 시대, 읽걷쓰 교육...   \n",
      "4     경복대 의료미용학과, 대학축제 맞아 유노성형외과 후원 '커피차 행사'...   \n",
      "5   “청렴하고 행정 능력 갖춘 金, 대장선에 타고 나홀로 싸워… 남은 12척...   \n",
      "6                     탈원전 앞장선 벨기에·덴마크 “다시 원전이다”   \n",
      "7           AI시대 동력… 李 “재생에너지 확대” 金 “원전 비율 2배로”   \n",
      "8                      중동 3국 돌고 나니 2791조원 ‘수퍼딜’   \n",
      "9              노동자 권리 지지했으나 마르크스주의엔 선 그은 레오 13세   \n",
      "\n",
      "                                                  본문  \n",
      "0  경기도교육청 남부신청사 컨슈머타임스=안우진 기자 | 경기도교육청(교육감 임태희)이 ...  \n",
      "1  TC본더는 인공지능(AI) 반도체용 HBM 제조에 필수적인 장비로, D램을 고정하는...  \n",
      "2  이를 바탕으로 생태자연 분야 데이터의 생산 및 분석 현황과 인공지능(AI), 디지털...  \n",
      "3  이번 특강은 도성훈 교육감이 지난 4월 콜롬비아를 방문해 인공지능(AI)·디지털 교...  \n",
      "4  경복대학교 의료미용학과는 'K-메디컬뷰티 실무 전문가 양성'을 교육 비전으로 삼고 ...  \n",
      "5  김 후보가 내게 의료와 AI(인공지능) 분야는 꼭 좀 맡아달라고 해서 힘을 쏟고 있...  \n",
      "6  AI(인공지능) 확산과 전기차 보급 등에 따라 2050년 전력 수요가 지금의 2배 ...  \n",
      "7  [3] 에너지 정책 어떻게 다른가 이재명 더불어민주당 후보와 김문수 국민의힘 후보의...  \n",
      "8  트럼프는 이날 마지막 순방국 아랍에미리트(UAE)에서 무함마드 빈 자이드 알 나하얀...  \n",
      "9  “오늘날 교회와 인류 사회는 인공지능(AI)의 급격한 발전이라는 새로운 산업혁명에 ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25058/4293506620.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  content = BeautifulSoup(item['description'].replace(\"<b>\", \"\").replace(\"</b>\", \"\"), \"html.parser\").text\n"
     ]
    }
   ],
   "source": [
    "# 판다스 데이터프레임으로 변환\n",
    "if response.status_code == 200 and 'items' in news_data:\n",
    "    # 데이터 준비\n",
    "    titles = []\n",
    "    contents = []\n",
    "    \n",
    "    for item in news_data['items']:\n",
    "        title = BeautifulSoup(item['title'].replace(\"<b>\", \"\").replace(\"</b>\", \"\"), \"html.parser\").text\n",
    "        content = BeautifulSoup(item['description'].replace(\"<b>\", \"\").replace(\"</b>\", \"\"), \"html.parser\").text\n",
    "        titles.append(title)\n",
    "        contents.append(content)\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame({\n",
    "        '제목': titles,\n",
    "        '본문': contents\n",
    "    })\n",
    "    \n",
    "    # 데이터프레임 출력\n",
    "    print(df)\n",
    "    \n",
    "    # 데이터프레임을 CSV 파일로 저장 (선택 사항)\n",
    "    # df.to_csv(f\"{query}_news.csv\", index=False, encoding='utf-8-sig')\n",
    "    # print(f\"'{query}_news.csv' CSV 파일로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
